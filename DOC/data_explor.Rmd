---
title: "Data Exploration"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
library(tidyverse)
library(here)
library(rsample)
devtools::load_all()
```

Import the data and explore. Working on issue 1.

```{r, warning=FALSE}
# raw_polls <- read_csv("/cloud/project/DATA/raw-polls.csv")
# gov_state <- read_csv(here("DATA/governor_state_forecast.csv"))
# gov_nat <- read_csv(here("DATA/governor_national_forecast.csv"))
# 
# # View(gov_state)
# # View(gov_nat)
```

After just an initial view of this data set, I don't think it is going to be feasible to pick out any one race from FiveThirtyEight's available data. It may be possible to do some type of simulation using their calculated probabilities and find some type of confidence intervals or something.

```{r}
# aug_sen <- read_csv(here("/DATA/august_senate_polls.csv"))
# 
# aug_sen %>% filter(state == "IN") %>% head()
```

This data set includes all polls for the senate races in different years from the month of August. This is a little out of date, but it could be somewhere to start if I want to do some type of simulation or analysis into the upcomming Indiana senate race. It may not yield great results, but it is at least raw polling data which I could use.

I don't think that FiveThirtyEight has a lot of their raw polling data on github for anyone to access. I may see if I can find just a couple polls which I could pull data from online. This will take a great deal more seaching, but I can use the FiveThirtyEight pollster raitings and the data from 'raw-polls.csv' to find out when polls were taken and if any of the polling firms are non-profits who regularly publish their results. 


# Explore Real Clear Politics data

```{r}
true_result <- 53.1-45.2
rcp_midterms <- read_csv(here("DATA","RCP_midterms.csv"))
rcp_midterms <- rcp_midterms %>% mutate(prop_diff = (Dem - Rep)/100, ord = 1:length(prop_diff),
                                        Dates = as.Date(Dates, "%m/%d/%Y", 
                                                        origin = as.Date("01/01/2017","%m/%d/%Y")),
                                        #tr_num_dates = trunc(as.numeric(Dates) - 17167, prec = -1)/10
                                        num_dates = as.numeric(Dates) - 17167,
                                        prob = num_dates/sum(num_dates),
                                        rel_Dem = Dem/(Dem + Rep), 
                                        rel_Rep = Rep/(Dem + Rep), 
                                        rel_diff = rel_Dem - rel_Rep,
                                        prob_full = double(length(prob)))

rcp_midterms$prob_full[rcp_midterms$SampType == "LV"] <-
  rcp_midterms$prob[rcp_midterms$SampType == "LV"] + 1/3/309

rcp_midterms$prob_full[rcp_midterms$SampType == "RV"] <-
  rcp_midterms$prob[rcp_midterms$SampType == "RV"] + 2/9/309

rcp_midterms$prob_full[rcp_midterms$SampType == "A"] <-
  rcp_midterms$prob[rcp_midterms$SampType == "A"] + 1/9/309
```


```{r}
prop_diff_est <- mean(rcp_midterms$prop_diff)


# Bootstrap procedure with no weights
# ntimes <- 1000
# boot_propdiff <- rerun(ntimes, sample(rcp_midterms$prop_diff, 
#                                       replace = TRUE))
# boot_dist <- map(boot_propdiff, mean) %>% flatten_dbl
# 
# sd(boot_dist)
# 
# ci_noweight <- quantile(boot_dist, c(.025, .975))
```

Doing a generalized linear model may be unreasonable considering I will end up having some negative values as my response is some difference in proportions. So, any kind of logarithmic link function will be invalid. 

I then started to do a basic bootstrap to simulate what different versions of an election would be, considering each poll to be a simulation of an election. But, I would like to place some type of wheighting or a probability vector to figure out how likely each poll could be selected. I think it would be best to weight by how recent the poll was taken before the election. I also noticed that I am leaving out valuable information by only bootstrapping the difference in proportions, as there is still the effect of the undecided voter. The difference between each party could be large, but if both only got about 30% of the vote, then there could be a decent number of undecideds.

So, I think I should use the `bootstraps()` command from the rsamples package to bootstrap entire rows from the dataset. 


```{r}
# Bootstrapping with weights

# boot_propdiff <- rerun(ntimes, sample(rcp_midterms$prop_diff, 
#                                       replace = TRUE,
#                                       prob = rcp_midterms$num_dates/sum(rcp_midterms$num_dates)))
# 
# boot_mean <- map(boot_propdiff, mean) %>% flatten_dbl
# mean(boot_mean)
# sd(boot_mean)
# ci_weight <- quantile(boot_mean, c(.025, .975))


w_est <- with(rcp_midterms, weighted.mean(prop_diff, w = prob)) # weighted estimate of proportion.


# Bootstrapping with keeping original percentages. 
new_boot <- bootstraps(rcp_midterms, times = 1000)

new_boot <- new_boot %>% 
  mutate(
    mean_diff = map_dbl(splits, 
                        ~ mean(analysis(.)$Dem - analysis(.)$Rep))
  )

ci_orig_perc <- quantile(new_boot$mean_diff, c(.025, .975))/100



```



After looking into some more literature, I found that a common strategy for those doing analysis on polls is to quantify the amount of support by dividing by the total of Democrats and Republicans. This gets rid of the undecided voters and third party voters. So, I will try to bootstrap with this new variable of difference in relative support. 

```{r}
relative_boot <- bootstraps(rcp_midterms, times = 1000)

relative_boot <- relative_boot %>% 
  mutate(
    mean_rel_diff = map_dbl(splits, 
                            ~ mean(analysis(.)$rel_diff))
  )
rel_est <- mean(rcp_midterms$rel_diff)

sd(relative_boot$mean_rel_diff)

ci_relative <- quantile(relative_boot$mean_rel_diff, c(.025, .975))
```


This turns out to be not too great of an estimate, even further bringing us from a realistic estimate. Though this is more similar to the models of other data scientists in the field.

```{r}
ggplot(data = rcp_midterms) + 
  geom_smooth(aes(x = Dates, y = Dem, weight = SampSize), color = "darkblue", se = FALSE) +
  geom_smooth(aes(x = Dates, y = Rep, weight = SampSize), color = "darkred", se = FALSE)


ggplot(data = rcp_midterms) + 
  geom_smooth(aes(x = Dates, y = rel_diff), se = FALSE)

ggplot(data = rcp_midterms) +
  geom_point(aes(x = Dates, y = prop_diff, color = SampType))
```


Some GLM stuff:

```{r}
mod1 <- glm(prop_diff ~ SampType + Dates, data = rcp_midterms, weights = SampSize)

rcp_midterms$prop_diff
summary(mod1)
plot(mod1)

mod1_df <- fortify(mod1)

ggplot(data = mod1_df) + geom_point(aes(x = .fitted, y = .stdresid))

ggplot(data = mod1_df) + geom_point(aes(x = Dates, y = .fitted, color = SampType))
```


What if I bootstrap just subsetting out polls of likely voters, which should hopefully give the most accurate results.

```{r}
ntimes = 1000
rcp_lv <- filter(rcp_midterms, SampType == "LV")

boot_lv <- rerun(ntimes, with(rcp_lv,sample(prop_diff, 
                                            replace = TRUE,
                                            prob = num_dates/sum(num_dates))))

boot_lv_dist <- map(boot_lv, mean) %>% flatten_dbl
lv_est <- with(rcp_lv, weighted.mean(prop_diff, num_dates/sum(num_dates)))
sd(boot_lv_dist)
ci_lv <- quantile(boot_lv_dist, c(.025, .975))



```


I have done some type of bootstrap a few times now, while only making slight changes. I should write a bootstrap function to call which will output a confidence interval.

```{r}
ci_lv <- with(rcp_lv, boot_ci_propdiff(prop_diff, prob = prob))
ci_weight <- with(rcp_midterms, boot_ci_propdiff(prop_diff, prob = prob))
ci_noweight <- with(rcp_midterms, boot_ci_propdiff(prop_diff))
ci_relative <- with(rcp_midterms, boot_ci_propdiff(rel_diff))


confints <- as.tibble(rbind(ci_noweight, ci_weight, ci_relative, ci_lv)) %>% 
  add_column(BootType = c("No Weights", "Weights", "Relative", "LikelyVoters")) %>%
  add_column(Est = c(prop_diff_est, w_est, rel_est, lv_est))




ggplot(data = confints) + 
  geom_hline(aes(yintercept = .056), linetype = "dashed", color = "blue", alpha = .5) +
  geom_pointrange(aes(x = BootType, y = Est, ymin = `2.5%`, ymax = `97.5%`)) +
  annotate("segment", x = "Relative", y = .06, xend = "Relative", yend = .0565, 
           arrow = arrow(), size=.4, alpha=.5, color = "blue") + 
  annotate("text", x = "Relative", y = 0.064, 
           label = "True Difference", color = "blue", alpha = .5) +
  scale_y_continuous(breaks = c(.05, .056, .06, .07, .08, .09)) + 
  coord_flip() + 
  labs(y = "Estimated Prop. Diff. (Dem - Rep)", title = "Comparing estimations of 2018 U.S. Midterms")

```

